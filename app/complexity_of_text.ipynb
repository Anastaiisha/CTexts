{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import statistics\n",
        "from collections import defaultdict\n",
        "from numpy import sqrt\n",
        "import pickle"
      ],
      "metadata": {
        "id": "J6ifE5-Sq2uh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import pymystem3\n",
        "from pydantic import BaseModel\n",
        "\n",
        "mystem = pymystem3.Mystem(entire_input=False, disambiguation=True)"
      ],
      "metadata": {
        "id": "vs9rW7_CGOb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34219ee-33aa-48dd-9920-112160b403b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import load\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn import linear_model\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "4c3YxMa4q6M_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9dfa394-b8cb-41e7-d0a8-b4b8140dd59c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5_p9gq6kWmp",
        "outputId": "67707f81-f989-4cf5-8643-76ef0e0da959"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VluRrgr7q0Kq"
      },
      "outputs": [],
      "source": [
        "class Analyzer:\n",
        "\n",
        "    COLUMNS_NEEDED_NATIVE = [\n",
        "        \"words\",\n",
        "        \"unique_words\",\n",
        "        \"sentences\",\n",
        "        \"characters\",\n",
        "        \"mean_len_word\",\n",
        "        \"mean_len_sentence\",\n",
        "        \"formula_flesh_oborneva\",\n",
        "        \"formula_flesh_kinc_oborneva\",\n",
        "        \"formula_pushkin\",\n",
        "        \"formula_pushkin_100\",\n",
        "        \"level_comment\",\n",
        "        \"structure_complex\",\n",
        "        \"lexical_complex\",\n",
        "        \"narrativity\",\n",
        "        \"description\",\n",
        "        \"tt_ratio\",\n",
        "        \"lex_density\",\n",
        "        \"lexical_complex_rki\",\n",
        "        \"detcorpus_5000\",\n",
        "        \"rare_words\",\n",
        "        'model',\n",
        "        \"Flesh_Kincaid\",\n",
        "        \"Gunning_fog\",\n",
        "        \"SMOG\",\n",
        "        \"Coleman_Liau\",\n",
        "        \"Dale_Chale\",\n",
        "    ]\n",
        "\n",
        "    GRAM_FEATURES = [\n",
        "        \"A\",\n",
        "        \"ADV\",\n",
        "        \"ADVPRO\",\n",
        "        \"ANUM\",\n",
        "        \"APRO\",\n",
        "        \"COM\",\n",
        "        \"CONJ\",\n",
        "        \"INTJ\",\n",
        "        \"NUM\",\n",
        "        \"PART\",\n",
        "        \"PR\",\n",
        "        \"S\",\n",
        "        \"SPRO\",\n",
        "        \"V\",\n",
        "        \"непрош\",\n",
        "        \"прош\",\n",
        "        \"им\",\n",
        "        \"пр\",\n",
        "        \"род\",\n",
        "        \"твор\",\n",
        "        \"деепр\",\n",
        "        \"изъяв\",\n",
        "        \"инф\",\n",
        "        \"пов\",\n",
        "        \"прич\",\n",
        "        \"кр\",\n",
        "        \"полн\",\n",
        "        \"притяж\",\n",
        "        \"1-л\",\n",
        "        \"сред\",\n",
        "        \"несов\",\n",
        "        \"сов\",\n",
        "        \"действ\",\n",
        "        \"страд\",\n",
        "        \"неод\",\n",
        "        \"од\",\n",
        "    ]\n",
        "\n",
        "    # шкала сложности, высчитывается от 0 до 10, примерно соответствует классу\n",
        "    INTERPRETER = [\n",
        "        (\"Очень простой текст, подойдет для возраста 7-8 лет (1-2 класс).\", 0, 20),\n",
        "        (\"Простой текст, подойдет для возраста 9-10 лет (3-4 класс).\", 20, 40),\n",
        "        (\"Достаточно простой текст, подойдет для возраста 11-12 лет (5-6 класс).\", 40, 60,),\n",
        "        (\"Текст подойдет для возраста 13-15 лет (7-9 класс).\", 60, 75),\n",
        "        (\"Текст подойдет для возраста 16-17 лет (10-11 класс).\", 75, 85),\n",
        "        (\"Сложный текст, подойдет для студента ВУЗа и старше\", 85, 91),\n",
        "        (\"Очень сложный текст, подойдет для выпускника ВУЗа и старше\", 91, 100),\n",
        "    ]\n",
        "\n",
        "    def __init__(self, mystem):\n",
        "      \n",
        "        self.mystem = mystem\n",
        "\n",
        "        self.ridge = linear_model.Ridge(alpha=0.1)\n",
        "\n",
        "        self.features = pd.read_csv(\"/content/drive/MyDrive/data/list_of_features_1207.csv\")\n",
        "\n",
        "        # списки частотных слов\n",
        "        self.fr_100_list = self.__load(\"/content/drive/MyDrive/data/fr_100.txt\")\n",
        "        self.fr_300_list = self.__load(\"/content/drive/MyDrive/data/fr_300.txt\")\n",
        "        self.fr_500_list = self.__load(\"/content/drive/MyDrive/data/fr_500.txt\")\n",
        "        self.fr_1000_list = self.__load(\"/content/drive/MyDrive/data/fr_1000.txt\")\n",
        "        self.fr_3000_list = self.__load(\"/content/drive/MyDrive/data/fr_3000.txt\")\n",
        "        self.fr_5000_list = self.__load(\"/content/drive/MyDrive/data/fr_5000.txt\")\n",
        "        self.fr_10000_list = self.__load(\"/content/drive/MyDrive/data/fr_10000.txt\")\n",
        "        self.fr_more_than_5list = self.__load(\"/content/drive/MyDrive/data/fr_more_than_5ipm.txt\")\n",
        "        self.fr_spoken_list = self.__load(\"/content/drive/MyDrive/data/fr_spoken.txt\")\n",
        "\n",
        "        # списки слов\n",
        "        self.simple_russian_850_list = self.__load(\"/content/drive/MyDrive/data/SimpleRussian850.txt\")\n",
        "        self.simple_russian_1000_list = self.__load(\"/content/drive/MyDrive/data/simple_russian.txt\")\n",
        "        self.simple_russian_2000_list = self.__load(\"/content/drive/MyDrive/data/SimpleRussian2000.txt\")\n",
        "        self.brown_russian_10000_list = self.__load(\"/content/drive/MyDrive/data/Brown10000.txt\")\n",
        "        self.dale_russian_3000_list = self.__load(\"/content/drive/MyDrive/data/DaleRussian3000.txt\")\n",
        "        self.stop_list = self.__load(\"/content/drive/MyDrive/data/stop_list.txt\")\n",
        "\n",
        "        # семантические списки\n",
        "        self.lex_abstract_list = self.__load(\"/content/drive/MyDrive/data/lex_abstract.txt\")\n",
        "\n",
        "        # списки слов для родного\n",
        "        self.laposhina_list = self.__load(\"/content/drive/MyDrive/data/laposhina_list_from_formula.txt\")\n",
        "        self.detcorpus_list = self.__load(\"/content/drive/MyDrive/data/detcorpus_5000.txt\")\n",
        "        self.rki_children_1000 = self.__load(\"/content/drive/MyDrive/data/children_list_1000.txt\")\n",
        "        self.rki_children_2000 = self.__load(\"/content/drive/MyDrive/data/children_list_2000.txt\")\n",
        "        self.rki_children_5000 = self.__load(\"/content/drive/MyDrive/data/children_list_5000.txt\")\n",
        "\n",
        "        # считали датафрейм\n",
        "        self.corpus_rnc = pd.read_csv(\"/content/drive/MyDrive/data/freq_rnc.csv\", quotechar=\"`\")\n",
        "        self.lemmas_list_rnc = list(self.corpus_rnc[\"lemma\"])\n",
        "\n",
        "        # создаем словарь и будем в него все складывать\n",
        "        self.data_about_text = {}\n",
        "        self.whole_lemmas_list = []\n",
        "        self.noun_list = []\n",
        "        self.bastard_list = []\n",
        "        self.obsc_list = []\n",
        "        self.razgovor_list = []\n",
        "        self.names_list = []\n",
        "        self.geo_name_list = []\n",
        "        self.conj_adversative_list = []  # противительные союзы\n",
        "        self.modal_words_list = []\n",
        "        self.words_length_list = []\n",
        "        self.number_of_syllables_list = []\n",
        "        self.long_words_list_3 = []  # слова более чем из 2 слогов\n",
        "        self.long_words_list = []  # слова более чем из 4 слогов\n",
        "        self.long_words_len_list_3 = []\n",
        "        self.long_words_len_list = []\n",
        "        self.count_kotoryi = []\n",
        "        self.count_content_pos = []\n",
        "        self.count_passive = []\n",
        "\n",
        "        # Обучаем модель\n",
        "        # x_train, y_train = self.features[ ], self.features[ ]\n",
        "        # self.ridge.fit(x_train, y_train)\n",
        "        # json.dump(self.ridge, \"data/model.joblib\")\n",
        "\n",
        "        # Загружаем уже обученную модель\n",
        "        with open('/content/vectorizer2.pk', 'rb') as f:\n",
        "          tfidf = pickle.load(f)\n",
        "\n",
        "        # загрузите преобразованные данные        \n",
        "        model = pickle.load(open('/content/model.sav', 'rb'))\n",
        "\n",
        "\n",
        "\n",
        "    def __load(self, file_name):\n",
        "        f = open(file_name, \"r\", encoding=\"utf_8\")\n",
        "        lines = f.readlines()\n",
        "        f.close()\n",
        "        return [line.replace(\"\\n\", \"\") for line in lines]\n",
        "\n",
        "    def __clean_text(self, input_text):\n",
        "        new_text = re.sub(r\"[-()\\\"#/@;:<>{}=~|]•\", \"\", input_text)\n",
        "        new_text = new_text.replace(\"­\\n\", \"\")\n",
        "        new_text = new_text.replace(\"\\n\", \" \")\n",
        "        new_text = new_text.replace(\"•\", \"\")\n",
        "        new_text = new_text.replace(\"…\", \".\")\n",
        "        new_text = new_text.replace(\"...\", \".\")\n",
        "        new_text = new_text.replace(\"..\", \".\")\n",
        "        new_text = new_text.replace(\"?.\", \"?\")\n",
        "        new_text = new_text.replace(\"!.\", \"!\")\n",
        "        new_text = new_text.replace(\"_\", \"\")\n",
        "        new_text = new_text.replace(\"!—\", \"! —\")\n",
        "        new_text = new_text.replace(\"?—\", \"? —\")\n",
        "        new_text = new_text.replace(\"\\xad\", \"\")\n",
        "        return new_text    \n",
        "       \n",
        "    # Подсчитываем слоги и буквы\n",
        "    SYLLABLES = [\"а\", \"е\", \"ё\", \"и\", \"о\", \"у\", \"ы\", \"ю\", \"я\", \"э\"]    \n",
        "    TWO_VOWELS = [\"ау\", \"ая\", \"аэ\", \"аю\", \"еа\", \"ее\", \"ею\", \"ея\", \"ие\", \"ии\", \"ио\", \"иу\", \"ию\", \"ия\", \"ое\", \"ою\", \"ую\", \"юю\", \"эт\", \"ые\", \"яя\", \"ье\", \"ья\"]\n",
        "    \n",
        "    def __count_syllables(self, element):\n",
        "        i_text = element.get(\"text\")\n",
        "        i_text_syl_counter = 0\n",
        "        for ii in i_text:\n",
        "            if ii in Analyzer.SYLLABLES:\n",
        "                i_text_syl_counter += 1\n",
        "        for i in Analyzer.TWO_VOWELS:\n",
        "            if i_text.find(i) != -1:\n",
        "                i_text_syl_counter -= 1\n",
        "        if i_text == \"его\":\n",
        "            i_text_syl_counter = 1\n",
        "        if i_text_syl_counter == 0:\n",
        "            i_text_syl_counter = 1\n",
        "        self.number_of_syllables_list.append(i_text_syl_counter)\n",
        "        self.words_length_list.append(len(i_text))\n",
        "        if i_text_syl_counter >= 3:\n",
        "            self.long_words_len_list_3.append(i_text_syl_counter)\n",
        "            self.long_words_list_3.append(i_text)\n",
        "        if i_text_syl_counter >= 4:\n",
        "            self.long_words_len_list.append(i_text_syl_counter)\n",
        "            self.long_words_list.append(i_text)\n",
        "        return True\n",
        "\n",
        "    # Убираем имена, геообъекты и бастарды\n",
        "    MODAL_WORDS = [ \"хочется\", \"нужно\", \"надо\", \"кажется\", \"казаться\", \"пожалуй\", \"хотеть\", \"должный\", \"хотется\"]\n",
        "\n",
        "    def __clean_from_name_geo_bastard(self, element):\n",
        "        self.whole_lemmas_list.append(element.get(\"analysis\")[0][\"lex\"])\n",
        "        gr_info = element.get(\"analysis\")[0][\"gr\"]\n",
        "        if \"qual\" in element.get(\"analysis\")[0]:\n",
        "            if element.get(\"analysis\")[0][\"qual\"] == \"bastard\":\n",
        "                self.bastard_list.append(element.get(\"text\"))\n",
        "        if gr_info.find(\"гео\") > 0:\n",
        "            self.geo_name_list.append(element.get(\"analysis\")[0][\"lex\"])\n",
        "        if gr_info.find(\"обсц\") > 0:\n",
        "            self.obsc_list.append(element.get(\"analysis\")[0][\"lex\"])\n",
        "        if gr_info.find(\"разг\") > 0:\n",
        "            self.razgovor_list.append(element.get(\"analysis\")[0][\"lex\"])\n",
        "        if (\n",
        "            gr_info.find(\"имя\") > 0\n",
        "            or gr_info.find(\"фам\") > 0\n",
        "            or gr_info.find(\"отч\") > 0\n",
        "        ):\n",
        "            self.names_list.append(element.get(\"analysis\")[0][\"lex\"])\n",
        "        if (\n",
        "            element.get(\"analysis\")[0][\"lex\"] == \"но\"\n",
        "            or element.get(\"analysis\")[0][\"lex\"] == \"а\"\n",
        "            or element.get(\"analysis\")[0][\"lex\"] == \"однако\"\n",
        "            or element.get(\"analysis\")[0][\"lex\"] == \"зато\"\n",
        "        ):\n",
        "            self.conj_adversative_list.append(element.get(\"analysis\")[0][\"lex\"])\n",
        "        if element.get(\"analysis\")[0][\"lex\"] in Analyzer.MODAL_WORDS:\n",
        "            self.modal_words_list.append(element.get(\"analysis\")[0][\"lex\"])\n",
        "        if element.get(\"analysis\")[0][\"lex\"] == \"который\":\n",
        "            self.count_kotoryi.append(element.get(\"analysis\")[0][\"lex\"])\n",
        "        return True\n",
        "\n",
        "    # подсчет грам. информации\n",
        "    def __count_gram(self, element):\n",
        "        gr_info = element.get(\"analysis\")[0][\"gr\"]\n",
        "        gr_info = gr_info.replace(\",\", \"<b>\")\n",
        "        gr_info = gr_info.replace(\"=\", \"<b>\")\n",
        "        gr_info = gr_info.split(\"<b>\")\n",
        "        for i in Analyzer.GRAM_FEATURES:\n",
        "            if i in gr_info:\n",
        "                self.dict_of_features[i] += 1\n",
        "        if \"S\" in gr_info:\n",
        "            self.noun_list.append(element.get(\"analysis\")[0][\"lex\"])\n",
        "        if \"S\" in gr_info or \"V\" in gr_info or \"A\" in gr_info or \"ADV\" in gr_info:\n",
        "            self.count_content_pos.append(element.get(\"analysis\")[0][\"lex\"])\n",
        "        return True\n",
        "\n",
        "    def __count_passive_form(self, element):\n",
        "        if element[0].get(\"analysis\") and element[1].get(\"analysis\"):\n",
        "            element0_gr = self.__get_gr_info(element[0])\n",
        "            element1_gr = self.__get_gr_info(element[1])\n",
        "            if element[0].get(\"analysis\")[0][\"lex\"] == \"быть\" and \"прош\" in element0_gr:\n",
        "                if \"прич\" in element1_gr:\n",
        "                    self.count_passive.append(element[1].get(\"text\"))\n",
        "        return True\n",
        "\n",
        "    def __get_gr_info(self, element):\n",
        "        gr_info = element.get(\"analysis\")[0][\"gr\"]\n",
        "        gr_info = gr_info.replace(\",\", \"<b>\")\n",
        "        gr_info = gr_info.replace(\"=\", \"<b>\")\n",
        "        gr_info = gr_info.split(\"<b>\")\n",
        "        return gr_info\n",
        "\n",
        "    # Общий цикл просмотра анализа слов\n",
        "    def __gram_analyze(self, element):\n",
        "        for i in element:\n",
        "            self.__count_syllables(i)\n",
        "            if len(i.get(\"analysis\")) > 0:\n",
        "                self.__clean_from_name_geo_bastard(i)\n",
        "                self.__count_gram(i)\n",
        "        return True\n",
        "\n",
        "    # Вычисляем процент слов из разных словников и частотных списков\n",
        "\n",
        "    def __percent_of_known_words_100(self, element, list_of_words):\n",
        "        if len(list_of_words) == 0 or len(element) == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            known_words = [w for w in element if w in list_of_words]\n",
        "            percent = round((len(known_words) / len(element)) * 100)\n",
        "            return percent\n",
        "\n",
        "\n",
        "    # делим текст на предложения\n",
        "    def __sent_tokenize_plus(self, this_text):\n",
        "        new_text = this_text.replace(\"(с.\", \"(стр \")\n",
        "        new_text = new_text.replace(\"на с.\", \"на стр\")\n",
        "        new_text = new_text.replace(\".—\", \". —\")\n",
        "        new_text = re.sub(r\"([a-zа-я1-9])\\.([A-ZА-Я])\", \"\\\\1. \\\\2\", new_text)\n",
        "        new_text = re.sub(r\"([a-zа-я1-9])\\!([A-ZА-Я])\", \"\\\\1! \\\\2\", new_text)\n",
        "        new_text = re.sub(r\"([a-zа-я1-9])\\?([A-ZА-Я])\", \"\\\\1? \\\\2\", new_text)\n",
        "        new_text = re.sub(r\"(рис. )([1-9])\", \"рис \\\\2\", new_text)\n",
        "        # В г. Смоленске\n",
        "        new_text = re.sub(r\"( г. )([A-ZА-Я]{1})\", \" г<dot> \\\\2\", new_text)\n",
        "        # С.В. Морозов\n",
        "        new_text = re.sub(\n",
        "            r\"([А-Я]{1}\\.[А-Я]{1})\\. ([A-ZА-Я]{1}[a-zа-я]+)\", \"\\\\1<dot> \\\\2\", new_text\n",
        "        )\n",
        "        # достигает 55 см. в длину\n",
        "        new_text = re.sub(r\"( см. )([a-zа-я1-9])\", \" см<dot> \\\\2\", new_text)\n",
        "\n",
        "        sentences = sent_tokenize(new_text)\n",
        "\n",
        "        new_sentences = []\n",
        "        for i in sentences:\n",
        "            # У лисички длина 3 м. А у котика - 2.\n",
        "            if re.findall(r\"([a-zа-я1-9])\\. ([А-Я]{1})\", i):\n",
        "                i_new = re.sub(r\"([a-zа-я1-9])\\. ([А-Я]{1})\", \"\\\\1.<stop>\\\\2\", i)\n",
        "                i_split = i_new.split(\"<stop>\")\n",
        "                for ii in i_split:\n",
        "                    new_sentences.append(ii)\n",
        "                continue\n",
        "            # И вы вырастили мух?- Нет пока.\n",
        "            if re.findall(r\"([a-zа-я1-9]\\.|\\?|\\!)(- [А-Я]{1})\", i):\n",
        "                i_new = re.sub(r\"([a-zа-я1-9]\\.|\\?|\\!)(- [А-Я]{1})\", \"\\\\1<stop>\\\\2\", i)\n",
        "                i_split = i_new.split(\"<stop>\")\n",
        "                for ii in i_split:\n",
        "                    new_sentences.append(ii)\n",
        "                continue\n",
        "            if re.findall(r\"[а-яА-ЯёЁ]+\", i):\n",
        "                new_sentences.append(i)\n",
        "\n",
        "        for i in new_sentences:\n",
        "            i = i.replace(\"<dot>\", \".\")\n",
        "        return new_sentences\n",
        "\n",
        "    def __clear_fields(self):\n",
        "\n",
        "        self.data_about_text = {}\n",
        "        self.whole_lemmas_list = []\n",
        "        self.noun_list = []\n",
        "        self.bastard_list = []\n",
        "        self.obsc_list = []\n",
        "        self.names_list = []\n",
        "        self.geo_name_list = []\n",
        "        self.conj_adversative_list = []  # противительные союзы\n",
        "        self.modal_words_list = []\n",
        "        self.words_length_list = []\n",
        "        self.number_of_syllables_list = []\n",
        "        self.long_words_list_3 = []  # слова более чем из 2 слогов\n",
        "        self.long_words_list = []  # слова более чем из 4 слогов\n",
        "        self.long_words_len_list = []\n",
        "        self.long_words_len_list_3 = []\n",
        "        self.count_kotoryi = []\n",
        "        self.count_content_pos = []\n",
        "        self.count_passive = []\n",
        "        return True\n",
        "\n",
        "    def __first_check_len_text(self, element):\n",
        "\n",
        "        # первая проверка текста - не слишком маленький\n",
        "        if len(element) < 10:\n",
        "            self.data_about_text[\"text_ok\"] = False\n",
        "            self.data_about_text[\n",
        "                \"text_error_message\"\n",
        "            ] = \"Введите текст на русском языке не менее 5 слов.\"\n",
        "            return self.data_about_text\n",
        "\n",
        "        # Вторая проверка текста - не слишком большой\n",
        "        if len(element) > 100000:\n",
        "            self.data_about_text[\"text_ok\"] = False\n",
        "            self.data_about_text[\n",
        "                \"text_error_message\"\n",
        "            ] = \"Введите текст не более 100 000 знаков.\"\n",
        "            return self.data_about_text\n",
        "\n",
        "        self.data_about_text[\"text_ok\"] = True\n",
        "        self.data_about_text[\"text_error_message\"] = \"\"\n",
        "\n",
        "        return self.data_about_text\n",
        "\n",
        "    def __second_check_len_text(self, element):\n",
        "        if len(element) < 5:\n",
        "            self.data_about_text[\"text_ok\"] = False\n",
        "            self.data_about_text[\n",
        "                \"text_error_message\"\n",
        "            ] = \"Введите текст на русском языке не менее 5 слов.\"\n",
        "            return self.data_about_text\n",
        "\n",
        "        self.data_about_text[\"text_ok\"] = True\n",
        "        self.data_about_text[\"text_error_message\"] = \"\"\n",
        "        return self.data_about_text\n",
        "     \n",
        "\n",
        "    # Корректный вывод !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    def __output_ball(self, ball):\n",
        "        ball_str = \"\"\n",
        "        if ball < 10:\n",
        "            last_number = ball\n",
        "            if last_number == 1:\n",
        "                ball_str = \"балл\"\n",
        "            if 2 <= last_number <= 4:\n",
        "                ball_str = \"балла\"\n",
        "            if 5 <= last_number <= 9:\n",
        "                ball_str = \"баллов\"\n",
        "        else:\n",
        "            last_number = ball % 10\n",
        "            if last_number == 1:\n",
        "                ball_str = \"балл\"\n",
        "            if 2 <= last_number <= 4:\n",
        "                ball_str = \"балла\"\n",
        "            if 5 <= last_number <= 9 or last_number == 0:\n",
        "                ball_str = \"баллов\"\n",
        "        return ball_str\n",
        "\n",
        "    def start_native(self, raw_text):\n",
        "        self.__clear_fields()\n",
        "\n",
        "        self.raw_text = raw_text\n",
        "\n",
        "        text = self.__clean_text(raw_text)\n",
        "\n",
        "        # создаем словарь и будем в него все складывать\n",
        "        self.dict_of_features = {}\n",
        "\n",
        "        # чистый финальный списочек параметров\n",
        "        self.data_about_text = {}\n",
        "\n",
        "        # первая проверка текста на длину\n",
        "        self.data_about_text = self.__first_check_len_text(text)\n",
        "\n",
        "        if self.data_about_text[\"text_ok\"] is False:\n",
        "            return self.data_about_text\n",
        "\n",
        "        self.sentences = self.__sent_tokenize_plus(text)\n",
        "        self.whole_analyzed_text = self.mystem.analyze(text)  # весь текст одним списком\n",
        "        analyzed_bigrams = list(nltk.bigrams(self.whole_analyzed_text))  # биграммочки\n",
        "\n",
        "        for i in Analyzer.GRAM_FEATURES:\n",
        "            self.dict_of_features[i] = 0\n",
        "\n",
        "        # запускаем функцию со всеми грам. анализами\n",
        "        self.__gram_analyze(self.whole_analyzed_text)\n",
        "\n",
        "        for i in analyzed_bigrams:\n",
        "            self.__count_passive_form(i)\n",
        "\n",
        "        # вторая проверка, не менее 5 слов\n",
        "        self.data_about_text = self.__second_check_len_text(self.whole_lemmas_list)\n",
        "        if self.data_about_text[\"text_ok\"] is False:\n",
        "            return self.data_about_text\n",
        "\n",
        "        self.clean_lemmas_list = [\n",
        "            f\n",
        "            for f in self.whole_lemmas_list\n",
        "            if f not in self.geo_name_list\n",
        "            and f not in self.names_list\n",
        "            and f not in self.bastard_list\n",
        "            and f not in self.stop_list\n",
        "        ]\n",
        "\n",
        "        all_words = len(self.whole_analyzed_text)\n",
        "        all_sentences = len(self.sentences)\n",
        "        all_syllables = sum(self.number_of_syllables_list)\n",
        "\n",
        "        all_len_words = [len(f) for f in self.whole_lemmas_list]\n",
        "        all_len_sentences = [len(f.split(\" \")) for f in self.sentences]\n",
        "\n",
        "        long_words = len(self.long_words_list)\n",
        "        whole_lemmas_minus_stop = [\n",
        "            f for f in self.whole_lemmas_list if f not in self.stop_list\n",
        "        ]\n",
        "        self.unique_lemmas_list = list(set(whole_lemmas_minus_stop))\n",
        "\n",
        "\n",
        "        # Цифры про текст:\n",
        "        # всего слов в тексте\n",
        "        self.dict_of_features[\"words\"] = len(self.whole_analyzed_text)\n",
        "        self.dict_of_features[\"characters\"] = len(self.raw_text)\n",
        "        self.dict_of_features[\"syllables\"] = all_syllables\n",
        "        self.dict_of_features[\"unique_words\"] = len(self.unique_lemmas_list)\n",
        "        # всего предложений в тексте\n",
        "        self.dict_of_features[\"sentences\"] = all_sentences\n",
        "        # средняя длина слова в тексте\n",
        "        self.dict_of_features[\"mean_len_word\"] = round(\n",
        "            ((sum(self.words_length_list)) / all_words), 1\n",
        "        )\n",
        "        self.dict_of_features[\"median_len_word\"] = statistics.median(all_len_words)\n",
        "        self.dict_of_features[\"median_len_sentence\"] = statistics.median(\n",
        "            all_len_sentences\n",
        "        )\n",
        "\n",
        "        # средняя длина предложения в тексте\n",
        "        self.dict_of_features[\"mean_len_sentence\"] = round(\n",
        "            (all_words / all_sentences), 1\n",
        "        )\n",
        "        self.dict_of_features[\"mean_len_word_in_syllables\"] = all_syllables / all_words\n",
        "        self.dict_of_features[\"percent_of_long_words\"] = long_words / all_words\n",
        "\n",
        "        # lexical density - лексическая плотность, соотношение смысловых и служебных\n",
        "        # частей речи: чем она выше, тем считается что текст сложнее\n",
        "        self.dict_of_features[\n",
        "            \"lex_density\"\n",
        "        ] = f\"{round((len(self.count_content_pos) / len(self.whole_lemmas_list)) * 10)} из 10\"\n",
        "\n",
        "        # type-token ratio (lexical diversity) - number of types/the number of tokens:\n",
        "        # чем выше, тем лексика в тексте \"однотипнее\"\n",
        "        # потом попробовать sttr: то же самое на отрезках в 1000 слов.\n",
        "        # standardised type/token ratio\n",
        "        self.dict_of_features[\"tt_ratio\"] = round(\n",
        "            ((len(self.unique_lemmas_list) / len(self.whole_lemmas_list))), 2\n",
        "        )\n",
        "\n",
        "        self.dict_of_features[\"passive\"] = len(self.count_passive)\n",
        "\n",
        "        # формулы читабельности (адаптированные, из диссера Оборневой)##\n",
        "        formula_f_oborneva_genuine = round(206.835 - (60.1 * (all_syllables / all_words)) - (1.3 * (all_words / all_sentences)))\n",
        "\n",
        "        formula_f_oborneva = formula_f_oborneva_genuine\n",
        "\n",
        "        if formula_f_oborneva > 100:\n",
        "            formula_f_oborneva = 100\n",
        "        if formula_f_oborneva < 0:\n",
        "            formula_f_oborneva = 0\n",
        "\n",
        "        self.dict_of_features[\"formula_flesh_oborneva\"] = f\"{formula_f_oborneva} из 100 (чем больше - тем текст легче)\"\n",
        "\n",
        "        formula_f_k_oborneva = round(0.5 * (all_words / all_sentences) + 8.4 * (all_syllables / all_words) - 15.59)\n",
        "\n",
        "        if formula_f_k_oborneva < 0:\n",
        "            formula_f_k_oborneva = 0\n",
        "\n",
        "        self.dict_of_features[\"formula_flesh_kinc_oborneva\"] = (f\"{formula_f_k_oborneva} (примерно должна \"\"соответствовать школьному классу)\")\n",
        "\n",
        "        in_laposhina_list = self.__percent_of_known_words_100(self.whole_lemmas_list, self.laposhina_list)\n",
        "\n",
        "        self.dict_of_features[\"laposhina_list\"] = f\"{in_laposhina_list} %\"\n",
        "\n",
        "        in_detcorpus_5000 = self.__percent_of_known_words_100(\n",
        "            self.whole_lemmas_list, self.detcorpus_list\n",
        "        )\n",
        "\n",
        "        self.dict_of_features[\"detcorpus_5000\"] = f\"{in_detcorpus_5000} %\"\n",
        "\n",
        "        self.dict_of_features[\"rare_words\"] = list(\n",
        "            set(\n",
        "                [\n",
        "                    f\n",
        "                    for f in self.clean_lemmas_list\n",
        "                    if f not in self.detcorpus_list and f not in self.fr_10000_list\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        structure_complex_genuine = round((100 - formula_f_oborneva_genuine + self.dict_of_features[\"прич\"] + self.dict_of_features[\"страд\"] + self.dict_of_features[\"passive\"]) / 10)\n",
        "\n",
        "        structure_complex = structure_complex_genuine\n",
        "\n",
        "        if structure_complex < 0:\n",
        "            structure_complex = 0\n",
        "        if structure_complex > 10:\n",
        "            structure_complex = 10\n",
        "\n",
        "        self.dict_of_features[\"structure_complex\"] = f\"{structure_complex} из 10\"\n",
        "\n",
        "        lexical_complex_genuine = round(10 - (((in_laposhina_list - 50) * 2) / 10))\n",
        "\n",
        "        lexical_complex = lexical_complex_genuine\n",
        "\n",
        "        if lexical_complex > 10:\n",
        "            lexical_complex = 10\n",
        "        if lexical_complex < 0:\n",
        "            lexical_complex = 0\n",
        "\n",
        "        self.dict_of_features[\"lexical_complex\"] = f\"{lexical_complex} из 10\"\n",
        "\n",
        "        lexical_complex_rki = round(10 - ((((in_detcorpus_5000 - 60) * 2)) / 10))\n",
        "\n",
        "        if lexical_complex_rki > 10:\n",
        "            lexical_complex_rki = 10\n",
        "        if lexical_complex_rki < 0:\n",
        "            lexical_complex_rki = 0\n",
        "\n",
        "        self.dict_of_features[\"lexical_complex_rki\"] = f\"{lexical_complex_rki} из 10\"\n",
        "\n",
        "        #Повествовательность\n",
        "        narrativity = round(10 - 2 * (self.dict_of_features[\"S\"] / (self.dict_of_features[\"V\"] + 1)))\n",
        "\n",
        "        if narrativity < 0:\n",
        "            narrativity = 0\n",
        "\n",
        "        self.dict_of_features[\"narrativity\"] = f\"{narrativity} из 10\"\n",
        "        \n",
        "\n",
        "        # Описательность\n",
        "        description = round(3 * (self.dict_of_features[\"A\"] / all_sentences))\n",
        "\n",
        "        if description > 10:\n",
        "            description = 10\n",
        "\n",
        "        self.dict_of_features[\"description\"] = f\"{description} из 10\"\n",
        "\n",
        "        \n",
        "        # Вычисляем и выводим формулу Пушкина\n",
        "        formula_pushkin_100 = round((((structure_complex_genuine + lexical_complex_genuine) * 5) - narrativity), 1,)\n",
        "\n",
        "        if formula_pushkin_100 > 100:\n",
        "            formula_pushkin_100 = 99\n",
        "        if formula_pushkin_100 < 1:\n",
        "            formula_pushkin_100 = 1\n",
        "\n",
        "        self.dict_of_features[\"formula_pushkin_100\"] = round(formula_pushkin_100)\n",
        "\n",
        "        self.dict_of_features[\"formula_pushkin\"] = round((formula_pushkin_100 / 10), 1)\n",
        "\n",
        "        if self.dict_of_features[\"formula_pushkin\"] < 1:\n",
        "            self.dict_of_features[\"formula_pushkin\"] = 1\n",
        "\n",
        "        ball = self.__output_ball(formula_pushkin_100)\n",
        "\n",
        "        # Константы SMOG Index http://en.wikipedia.org/wiki/SMOG\n",
        "        SMOG_X_GRADE = 1.1\n",
        "        SMOG_Y_GRADE = 64.6\n",
        "        SMOG_Z_GRADE = 0.05\n",
        "        # Coleman Liau константы. Подробнее http://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index\n",
        "        CLI_X_GRADE = 0.055\n",
        "        CLI_Y_GRADE = 0.35\n",
        "        CLI_Z_GRADE = 20.33        \n",
        "        \n",
        "        n_psyl = len(self.long_words_list_3)\n",
        "        \n",
        "        self.dict_of_features[\"Flesh_Kincaid\"] = round(0.49 * (float(all_words) / all_sentences) + 7.3 * (float(all_syllables) / all_words) - 16.59)\n",
        "        self.dict_of_features[\"Gunning_fog\"] = round(0.4 * ((float(all_words)/ all_sentences) + 100 * (float(n_psyl) / all_words)))\n",
        "        self.dict_of_features[\"SMOG\"] = round(SMOG_X_GRADE * sqrt((float(SMOG_Y_GRADE) / all_sentences) * n_psyl) + SMOG_Z_GRADE) # корректно при наличии более 30 предложений\n",
        "        Coleman_Liau = round(0.055 * (all_syllables * (100.0 / all_words)) - 0.35 * (all_sentences * (100.0 / all_words)) - 20.33)\n",
        "        self.dict_of_features[\"Coleman_Liau\"] = abs(Coleman_Liau)\n",
        "        self.dict_of_features[\"Dale_Chale\"] = round(0.552 * (100.0 * n_psyl / all_words) + 0.273 * (float(all_words) / all_sentences))\n",
        "\n",
        "        for i in Analyzer.INTERPRETER:\n",
        "            if i[1] < formula_pushkin_100 <= i[2]:\n",
        "                self.dict_of_features[\"level_comment\"] = f\"{round(formula_pushkin_100)} {ball} из 100. {i[0]}\"\n",
        "        \n",
        "        with open('/content/vectorizer2.pk', 'rb') as f:\n",
        "          tfidf = pickle.load(f)\n",
        "          \n",
        "        # загрузите преобразованные данные        \n",
        "        model = pickle.load(open('/content/model.sav', 'rb'))\n",
        "\n",
        "        text = [raw_text]\n",
        "        text_features = tfidf.transform(text)\n",
        "        predictions = model.predict(text_features)\n",
        "        \n",
        "        self.dict_of_features[\"model\"] = ''.join(predictions)\n",
        "        \n",
        "        for i in self.dict_of_features:\n",
        "            if i in Analyzer.COLUMNS_NEEDED_NATIVE:\n",
        "                self.data_about_text[i] = self.dict_of_features[i]\n",
        "\n",
        "        return self.data_about_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка текста\n",
        "analyzer = Analyzer(mystem)\n",
        "result = analyzer.start_native(raw)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPNcFTCB4jKu",
        "outputId": "260b4f30-1966-44e9-d84b-01f925a69a63"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text_ok': True,\n",
              " 'text_error_message': '',\n",
              " 'words': 144,\n",
              " 'characters': 1201,\n",
              " 'unique_words': 113,\n",
              " 'sentences': 8,\n",
              " 'mean_len_word': 7.1,\n",
              " 'mean_len_sentence': 18.0,\n",
              " 'lex_density': '7 из 10',\n",
              " 'tt_ratio': 0.78,\n",
              " 'formula_flesh_oborneva': '13 из 100 (чем больше - тем текст легче)',\n",
              " 'formula_flesh_kinc_oborneva': '17 (примерно должна соответствовать школьному классу)',\n",
              " 'detcorpus_5000': '67 %',\n",
              " 'rare_words': ['издержка',\n",
              "  'учредительный',\n",
              "  'трансакционный',\n",
              "  'внутрифирменный',\n",
              "  'интерспецифический',\n",
              "  'организоваться',\n",
              "  'тыс',\n",
              "  'реализовывать',\n",
              "  'совокупный',\n",
              "  'правомочие',\n",
              "  'согласовываться',\n",
              "  'долл',\n",
              "  'отношенческий'],\n",
              " 'structure_complex': '9 из 10',\n",
              " 'lexical_complex': '8 из 10',\n",
              " 'lexical_complex_rki': '9 из 10',\n",
              " 'narrativity': '5 из 10',\n",
              " 'description': '8 из 10',\n",
              " 'formula_pushkin_100': 80,\n",
              " 'formula_pushkin': 8.0,\n",
              " 'Flesh_Kincaid': 13,\n",
              " 'Gunning_fog': 29,\n",
              " 'SMOG': 28,\n",
              " 'Coleman_Liau': 7,\n",
              " 'Dale_Chale': 36,\n",
              " 'level_comment': '80 баллов из 100. Текст подойдет для возраста 16-17 лет (10-11 класс).',\n",
              " 'model': 'Старшие классы'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in result.items():\n",
        "  print(\"{0}: {1}\".format(key,value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1i3QbBvy-Z6",
        "outputId": "c7efdb0e-1bb5-47e7-9c09-f8b2b04a0dfa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_ok: True\n",
            "text_error_message: \n",
            "words: 144\n",
            "characters: 1201\n",
            "unique_words: 113\n",
            "sentences: 8\n",
            "mean_len_word: 7.1\n",
            "mean_len_sentence: 18.0\n",
            "lex_density: 7 из 10\n",
            "tt_ratio: 0.78\n",
            "formula_flesh_oborneva: 13 из 100 (чем больше - тем текст легче)\n",
            "formula_flesh_kinc_oborneva: 17 (примерно должна соответствовать школьному классу)\n",
            "detcorpus_5000: 67 %\n",
            "rare_words: ['издержка', 'учредительный', 'трансакционный', 'внутрифирменный', 'интерспецифический', 'организоваться', 'тыс', 'реализовывать', 'совокупный', 'правомочие', 'согласовываться', 'долл', 'отношенческий']\n",
            "structure_complex: 9 из 10\n",
            "lexical_complex: 8 из 10\n",
            "lexical_complex_rki: 9 из 10\n",
            "narrativity: 5 из 10\n",
            "description: 8 из 10\n",
            "formula_pushkin_100: 80\n",
            "formula_pushkin: 8.0\n",
            "Flesh_Kincaid: 13\n",
            "Gunning_fog: 29\n",
            "SMOG: 28\n",
            "Coleman_Liau: 7\n",
            "Dale_Chale: 36\n",
            "level_comment: 80 баллов из 100. Текст подойдет для возраста 16-17 лет (10-11 класс).\n",
            "model: Старшие классы\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict (result, orient='index').reset_index()\n",
        "df.columns = ['name', 'result']\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "WM3NlGaWzRKv",
        "outputId": "40a3940e-2610-4e7c-b5ee-c1ab41774de4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           name  \\\n",
              "0                       text_ok   \n",
              "1            text_error_message   \n",
              "2                         words   \n",
              "3                    characters   \n",
              "4                  unique_words   \n",
              "5                     sentences   \n",
              "6                 mean_len_word   \n",
              "7             mean_len_sentence   \n",
              "8                   lex_density   \n",
              "9                      tt_ratio   \n",
              "10       formula_flesh_oborneva   \n",
              "11  formula_flesh_kinc_oborneva   \n",
              "12               detcorpus_5000   \n",
              "13                   rare_words   \n",
              "14            structure_complex   \n",
              "15              lexical_complex   \n",
              "16          lexical_complex_rki   \n",
              "17                  narrativity   \n",
              "18                  description   \n",
              "19          formula_pushkin_100   \n",
              "20              formula_pushkin   \n",
              "21                Flesh_Kincaid   \n",
              "22                  Gunning_fog   \n",
              "23                         SMOG   \n",
              "24                 Coleman_Liau   \n",
              "25                   Dale_Chale   \n",
              "26                level_comment   \n",
              "27                        model   \n",
              "\n",
              "                                               result  \n",
              "0                                                True  \n",
              "1                                                      \n",
              "2                                                 144  \n",
              "3                                                1201  \n",
              "4                                                 113  \n",
              "5                                                   8  \n",
              "6                                                 7.1  \n",
              "7                                                18.0  \n",
              "8                                             7 из 10  \n",
              "9                                                0.78  \n",
              "10           13 из 100 (чем больше - тем текст легче)  \n",
              "11  17 (примерно должна соответствовать школьному ...  \n",
              "12                                               67 %  \n",
              "13  [издержка, учредительный, трансакционный, внут...  \n",
              "14                                            9 из 10  \n",
              "15                                            8 из 10  \n",
              "16                                            9 из 10  \n",
              "17                                            5 из 10  \n",
              "18                                            8 из 10  \n",
              "19                                                 80  \n",
              "20                                                8.0  \n",
              "21                                                 13  \n",
              "22                                                 29  \n",
              "23                                                 28  \n",
              "24                                                  7  \n",
              "25                                                 36  \n",
              "26  80 баллов из 100. Текст подойдет для возраста ...  \n",
              "27                                     Старшие классы  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee611f69-ed9e-41f8-a284-06be9c4145a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>text_ok</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>text_error_message</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>words</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>characters</td>\n",
              "      <td>1201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>unique_words</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sentences</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>mean_len_word</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>mean_len_sentence</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>lex_density</td>\n",
              "      <td>7 из 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tt_ratio</td>\n",
              "      <td>0.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>formula_flesh_oborneva</td>\n",
              "      <td>13 из 100 (чем больше - тем текст легче)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>formula_flesh_kinc_oborneva</td>\n",
              "      <td>17 (примерно должна соответствовать школьному ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>detcorpus_5000</td>\n",
              "      <td>67 %</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>rare_words</td>\n",
              "      <td>[издержка, учредительный, трансакционный, внут...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>structure_complex</td>\n",
              "      <td>9 из 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>lexical_complex</td>\n",
              "      <td>8 из 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>lexical_complex_rki</td>\n",
              "      <td>9 из 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>narrativity</td>\n",
              "      <td>5 из 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>description</td>\n",
              "      <td>8 из 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>formula_pushkin_100</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>formula_pushkin</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Flesh_Kincaid</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Gunning_fog</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>SMOG</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Coleman_Liau</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Dale_Chale</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>level_comment</td>\n",
              "      <td>80 баллов из 100. Текст подойдет для возраста ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>model</td>\n",
              "      <td>Старшие классы</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee611f69-ed9e-41f8-a284-06be9c4145a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee611f69-ed9e-41f8-a284-06be9c4145a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee611f69-ed9e-41f8-a284-06be9c4145a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Текст\n",
        "raw = \"Партнерства являются менее распространенной формой организации бизнеса: в США на их долю приходится около 7% всех фирм, а их годовой оборот составляет порядка 4% от совокупного в национальной экономике. Однако величина их среднего дохода на одну фирму почти в четыре раза превышает аналогичный показатель для индивидуальных владений, достигая уровня 166 тыс. долл. в год. Поскольку партнерство, в отличие от индивидуального владения, организуется и управляется несколькими собственниками, отношения между ними по своей экономической природе представляют собой сеть отношенческих контрактов между владельцами интерспецифических ресурсов. Формальными (письменными) проявлениями данных отношений являются учредительный договор и устав фирмы, однако неформальные соглашения между партнерами имеют более существенное значение, особенно в текущей деятельности фирмы. Поскольку в партнерстве существует несколько владельцев, каждый из них может реализовывать любое из прав собственности, составляющих известный нам пучок правомочий, однако нужно учесть, что такого рода действия должны согласовываться с остальными партнерами. Это обстоятельство приводит к увеличению внутрифирменных трансакционных издержек.\""
      ],
      "metadata": {
        "id": "igtpaM401MDZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   Метрики удобочитаемости:\n",
        "\n",
        "    def calc_Flesh_Kincaid_Grade_rus(all_words, all_syllables, all_sentences):\n",
        "      \"\"\"Метрика Flesh Kincaid Grade для русского языка\"\"\"\n",
        "#     n = 0.59 * (float(all_words) / all_sentences) + 6.2 * (float(all_syllables) / all_words) - 16.59\n",
        "      n = 0.49 * (float(all_words) / all_sentences) + 7.3 * (float(all_syllables) / all_words) - 16.59\n",
        "      return n\n",
        "\n",
        "    # n_psyl - слова более чем с 2 слогами (long_words_len_list_3)\n",
        "    def calc_Gunning_fog(n_psyl, all_words, all_sentences):\n",
        "      \"\"\"Метрика Gunning fog для английского языка\"\"\"\n",
        "      n = 0.4 * ((float(all_words)/ all_sentences) + 100 * (float(n_psyl) / all_words))\n",
        "      return n\n",
        "\n",
        "    # Константы SMOG Index http://en.wikipedia.org/wiki/SMOG\n",
        "    SMOG_X_GRADE = 1.1\n",
        "    SMOG_Y_GRADE = 64.6\n",
        "    SMOG_Z_GRADE = 0.05\n",
        "\n",
        "    def calc_SMOG_index(n_psyl, all_sentences):\n",
        "      \"\"\"Метрика SMOG для русского языка\"\"\"\n",
        "      if all_sentences == 0: \n",
        "        return 0\n",
        "      else:\n",
        "        n = SMOG_X_GRADE * sqrt((float(SMOG_Y_GRADE) / all_sentences) * n_psyl) + SMOG_Z_GRADE\n",
        "        return n\n",
        "\n",
        "    # Coleman Liau константы. Подробнее http://en.wikipedia.org/wiki/Coleman%E2%80%93Liau_index\n",
        "    CLI_X_GRADE = 0.055\n",
        "    CLI_Y_GRADE = 0.35\n",
        "    CLI_Z_GRADE = 20.33\n",
        "\n",
        "    def calc_Coleman_Liau_index_adapted(all_syllables, all_words, all_sentences):\n",
        "      \"\"\" Метрика Coleman Liau для русского языка с адаптированными параметрами \"\"\"\n",
        "      if all_words == 0: return 0\n",
        "      n = 0.055 * (all_syllables * (100.0 / all_words)) - 0.35 * (all_sentences * (100.0 / all_words)) - 20.33\n",
        "      return n\n",
        "\n",
        "    def calc_Coleman_Liau_index(all_syllables, all_words, all_sentences):\n",
        "      \"\"\" Метрика Coleman Liau для русского языка с константными параметрами \"\"\"\n",
        "      if all_words == 0: return 0\n",
        "      n = CLI_X_GRADE * (all_syllables * (100.0 / all_words)) - CLI_Y_GRADE * (all_sentences * (100.0 / all_words)) - CLI_Z_GRADE\n",
        "      return n"
      ],
      "metadata": {
        "id": "POhjaPK1gTJK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}